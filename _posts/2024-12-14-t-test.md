---
title:  "T-test "
mathjax: true
layout: post
categories: media
---

In this post, we'll try to answer these questions:
What is T-Test?
What is its application?
What is t-statistics?
What is the difference between a t-statistic and the critical value"?
How to do it in Scipy?
How to do it in R?

### What is T-test?
Is a test that test the hypothesis of a mean value. It answer questions such as:
- Is the group of students score significantly higher than usual?
- Is two the treated patients have better measurement then the control group?
  
### What is its application?
It's for testing hypothesis about $\overline{x}$, the mean of some data. It could be the mean score of a class, or comparing the mean scores of two classes.


### What is t-distribution?
We still need to construct a curve and calculate the probability. To do that, we pick a distribution, t-distribution:

![T-distribution](/images/t-distribution.png)

The reason of picking this distribution instead of Normal have something to do of the fact that we are forced to use sample variance s in place of population variance $\sigma$. It need a fatter tail for some reason.

Degree of freedom is chosen as $n-1$. Don't know why.

### What is t-statistics?
After we have a curve and a point estimate, a statistic is how many standard error away are the point estimate from the null value:
$$
statistic = \frac{(PointEstimate - NullValue)}{StandardError}
$$
Stats table is usually a lookup table by this statistic and give us the one-sided or two-sided p-values.
### How to do it in Scipy?

One-sample
```python
from scipy.stats import ttest_1samp

# Example Data
data = [5.3, 5.5, 6.1, 5.8, 5.0, 5.7]

# One-sample t-test
t_stat, p_value = ttest_1samp(data, popmean=5.5)  # `popmean` is the hypothesized mean

print(f"T-statistic: {t_stat}, P-value: {p_value}")
```

Two-sample (non-paired, independent groups)

```python
from scipy.stats import ttest_ind

# Example Data
group1 = [2.4, 2.5, 2.8, 2.7, 2.6]
group2 = [3.1, 3.4, 3.3, 3.5, 3.2]

# Two-sample t-test
t_stat, p_value = ttest_ind(group1, group2, equal_var=True)  # `equal_var=True` assumes equal variance

print(f"T-statistic: {t_stat}, P-value: {p_value}")
```

By default, `ttest_ind` and `ttest_rel` (it's for paired groups, but same api) do two-sided test, use this parameter to change to one-sided:

```python
ttest_ind(group1, group2, alternative='greater') # or 'less'
```

Example output
```
T-statistic: -8.944, P-value: 0.00002
```
- **T-statistic**: Indicates the magnitude of the difference relative to variability. A larger absolute value means a more substantial difference.
- **P-value**: If this value is less than 0.05 (default significance level), the result is statistically significant.

### What is the difference between a t-statistic and the critical value?
This question is asking about how far away a t-statistic is from a null value.
The critical value is the t-statistic of the 0.05 probability. Since its not a normal distribution, we need the degree of freedom. 

```python
from scipy.stats import ttest_ind, t

# Example data for two independent samples
group1 = [2.4, 2.5, 2.8, 2.7, 2.6]
group2 = [3.1, 3.4, 3.3, 3.5, 3.2]

# Perform a two-sample t-test
t_stat, p_value = ttest_ind(group1, group2, equal_var=True)

# Degrees of freedom
n1, n2 = len(group1), len(group2)
df = n1 + n2 - 2  # degrees of freedom for two-sample t-test

# Get the critical t-value for alpha = 0.05 (two-tailed)
critical_t = t.ppf(1 - 0.05 / 2, df)

# Calculate the absolute difference between the t-statistic and the critical t-value
abs_diff = abs(abs(t_stat) - critical_t)

# Print results
print(f"T-statistic: {t_stat}")
print(f"Critical t-value (0.05): {critical_t}")
print(f"Absolute difference: {abs_diff}")
```

```
T-statistic: -8.944
Critical t-value (0.05): 2.306004
Absolute difference: 6.637996
```

### How to do it in R?
R's relevant function includes:
`t.test(group1, group2, var.equal = TRUE, paired = TRUE)`
`qt(p, df, lower.tail = TRUE)`

